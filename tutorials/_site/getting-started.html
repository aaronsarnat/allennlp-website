<p>Welcome to AllenNLP!</p>

<h2 id="installing-using-docker">Installing using Docker</h2>

<p>The easiest way to get started is using Docker. Assuming you have Docker installed, just run</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>docker run -p 8000:8000 -it --rm allennlp/allennlp
</code></pre>
</div>

<p>This will download the latest <code class="highlighter-rouge">allennlp</code> image to your machine
(unless you already have it),
start a Docker container, and launch an interactive shell.
It also exposes port 8000, which is where the demo server runs,
and shuts down the container when you exit the interactive shell.</p>

<h2 id="installing-not-using-docker">Installing Not Using Docker</h2>

<p>If you can’t (or don’t want to) use Docker, you can clone from our git repository:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>git clone https://github.com/allenai/allennlp.git
</code></pre>
</div>

<p>Create a Python 3.5 (or 3.6) virtual environment, and run</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="nv">INSTALL_TEST_REQUIREMENTS</span><span class="o">=</span><span class="nb">true </span>scripts/install_requirements.sh
</code></pre>
</div>

<p>changing the flag to <code class="highlighter-rouge">false</code> if you don’t want to be able to run tests.
(Narrator: You want to be able to run tests.)</p>

<p>You’ll also need to install PyTorch 0.2, following the appropriate instructions
from <a href="http://pytorch.org/">their website</a>.</p>

<h2 id="once-youve-installed">Once You’ve Installed</h2>

<p>A lot of the most common functionality can be accessed through the command line tool <code class="highlighter-rouge">allennlp/run</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>$ allennlp/run
usage: run [command]

Run AllenNLP

optional arguments:
  -h, --help  show this help message and exit

Commands:

    predict   Use a trained model to make predictions.
    train     Train a model
    serve     Run the web service and demo.
    evaluate  Evaluate the specified model + dataset
</code></pre>
</div>

<h3 id="serving-the-demo">Serving the Demo</h3>

<p>The <code class="highlighter-rouge">serve</code> command starts the demo server.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>$ allennlp/run serve
Starting a sanic server on port 8000.
[... lots of logging omitted ...]
2017-08-16 18:55:12 - (sanic)[INFO]: Goin' Fast @ http://0.0.0.0:8000
2017-08-16 18:55:12,321 - INFO - sanic - Goin' Fast @ http://0.0.0.0:8000
2017-08-16 18:55:12 - (sanic)[INFO]: Starting worker [33290]
2017-08-16 18:55:12,323 - INFO - sanic - Starting worker [33290]
</code></pre>
</div>

<p>If you visit <code class="highlighter-rouge">http://localhost:8000</code> in your browser, you can play around with the same demo
that runs on the AllenNLP website.</p>

<p>TODO(joelgrus): screenshot</p>

<h3 id="training-a-model">Training a Model</h3>

<p>In this tutorial we’ll train a simple part-of-speech tagger using AllenNLP.
The model is defined in <a href="https://github.com/allenai/allennlp/blob/master/allennlp/models/simple_tagger.py">allennlp/models/simple_tagger.py</a>.
It consists of a word embedding layer followed by an LSTM.</p>

<p>Our dataset will be a subset of the <a href="http://www.nltk.org/nltk_data/">Brown Corpus</a>.
In particular, we will train a model on 4000 randomly chosen sentences (<code class="highlighter-rouge">sentences.small.train</code>) and use a different 1000 randomly chosen sentences
as the validation set (<code class="highlighter-rouge">sentences.small.dev</code>).</p>

<p>In AllenNLP we configure experiments using JSON files. Our experiment is defined in
<a href="https://github.com/allenai/allennlp/blob/master/tutorials/getting_started/simple_tagger.json">tutorials/getting_started/simple_tagger.json</a>. You can peek at it
if you want, we’ll go through it in detail in the next tutorial.  Right at this instant
you might care about the <code class="highlighter-rouge">trainer</code> section, which specifies how we want to train our model:</p>

<div class="language-js highlighter-rouge"><pre class="highlight"><code>  <span class="s2">"trainer"</span><span class="err">:</span> <span class="p">{</span>
    <span class="s2">"num_epochs"</span><span class="err">:</span> <span class="mi">40</span><span class="p">,</span>
    <span class="s2">"patience"</span><span class="err">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">"cuda_device"</span><span class="err">:</span> <span class="o">-</span><span class="mi">1</span>
  <span class="p">}</span>
</code></pre>
</div>

<p>Here the <code class="highlighter-rouge">num_epochs</code> parameter specifies that we want to make 40 training passes through the training dataset.
On a recent Macbook each epoch of this model on this dataset takes about a minute,
so this training should take about 40, unless it stops early. <code class="highlighter-rouge">patience</code>
controls the early stopping – if our validation metric doesn’t improve for
this many epochs, training halts. And if you have a GPU you can change <code class="highlighter-rouge">cuda_device</code> to 0 to use it.</p>

<p>Change any of those if you want to, and then run</p>

<div class="highlighter-rouge"><pre class="highlight"><code>allennlp/run train tutorials/getting_started/simple_tagger.json --serialization_dir /tmp/tutorials/getting_started
</code></pre>
</div>

<p>The <code class="highlighter-rouge">serialization_dir</code> argument specifies the directory where the model’s vocabulary and checkpointed weights will be saved.</p>

<p>This command will download the datasets and cache them locally,
log all of the parameters it’s using,
and then display the progress and results of each epoch:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>2017-08-23 18:07:14,700 - INFO - allennlp.training.trainer - Epoch 2/40
accuracy: 0.51, loss: 2.06, accuracy3: 0.67 ||: 100%|##########| 125/125 [01:08&lt;00:00,  2.03it/s]
accuracy: 0.61, loss: 1.65, accuracy3: 0.75 ||: 100%|##########| 32/32 [00:06&lt;00:00,  4.96it/s]
2017-08-23 18:08:29,397 - INFO - allennlp.training.trainer - Training accuracy : 0.506099    Validation accuracy : 0.606811
2017-08-23 18:08:29,398 - INFO - allennlp.training.trainer - Training loss : 2.061412    Validation loss : 1.646712
2017-08-23 18:08:29,398 - INFO - allennlp.training.trainer - Training accuracy3 : 0.672000    Validation accuracy3 : 0.753761
2017-08-23 18:08:29,423 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to /tmp/tutorials/getting_started/best.th'.
</code></pre>
</div>

<p>Here <code class="highlighter-rouge">accuracy</code> measures how often our model predicted the “correct” part of speech tag as most probable,
while <code class="highlighter-rouge">accuracy3</code> measures how often the correct tag was one of the <em>three</em> most probable.
<code class="highlighter-rouge">loss</code> measures <a href="https://en.wikipedia.org/wiki/Cross_entropy">cross entropy</a>
 and is the objective being used to train the model. You want to make sure
 it’s mostly decreasing during training.</p>

<p>After 30 epochs the performance on the validation set seems to top out:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>2017-08-23 18:40:46,632 - INFO - allennlp.training.trainer - Epoch 30/40
accuracy: 0.97, loss: 0.10, accuracy3: 1.00 ||: 100%|##########| 125/125 [01:04&lt;00:00,  1.86it/s]
accuracy: 0.92, loss: 0.40, accuracy3: 0.97 ||: 100%|##########| 32/32 [00:05&lt;00:00,  5.58it/s]
2017-08-23 18:41:57,236 - INFO - allennlp.training.trainer - Training accuracy : 0.966363    Validation accuracy : 0.916993
2017-08-23 18:41:57,236 - INFO - allennlp.training.trainer - Training loss : 0.098178    Validation loss : 0.401380
2017-08-23 18:41:57,237 - INFO - allennlp.training.trainer - Training accuracy3 : 0.995176    Validation accuracy3 : 0.973490
</code></pre>
</div>

<p>This means that 92% of the time our model predicted the correct tag on the validation dataset,
and 97% of the time the correct tag was in the model’s “top 3”.
Not ground-breaking performance, but this is a pretty simple model, and
if you look at the data there’s a lot of different tags!</p>

<p>Now that the model is trained, there should be a bunch of files in the serialization directory. The <code class="highlighter-rouge">vocabulary</code> directory
contains the model’s vocabularies, each of which is a (distinct) encoding of strings as integers.
In our case, we’ll have one for <code class="highlighter-rouge">tokens</code> (i.e. words) and another for <code class="highlighter-rouge">tags</code>. The various
<code class="highlighter-rouge">training_state_epoch_XX.th</code> files contain the state of the trainer after each epoch (<code class="highlighter-rouge">.th</code> is the suffix for serialized torch tensors),
so that you could resume training where you left off, if you wanted to.
Similarly, the <code class="highlighter-rouge">model_state_epoch_XX.th</code> files contain the model weights after each epoch.
<code class="highlighter-rouge">best.th</code> contains the <em>best</em> weights (that is, those from the epoch with the smallest <code class="highlighter-rouge">loss</code> on the validation dataset).</p>

<p>Finally, there is an “archive” file <code class="highlighter-rouge">model.tar.gz</code> that contains the training configuration,
the <code class="highlighter-rouge">best</code> weights, and the <code class="highlighter-rouge">vocabulary</code>.</p>

<h3 id="evaluating-a-model">Evaluating a Model</h3>

<p>Once you’ve trained a model, you likely want to evaluate it on another dataset.
We have another 1000 sentences in the file <code class="highlighter-rouge">sentences.small.test</code>, which
is shared publicly on Amazon S3.</p>

<p>We can use the <code class="highlighter-rouge">allennlp/run evaluate</code> command, giving it the archived model and the evaluation dataset:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>$ allennlp/run evaluate --archive_file /tmp/tutorials/getting_started/model.tar.gz --evaluation_data_file https://allennlp.s3.amazonaws.com/datasets/getting-started/sentences.small.test
</code></pre>
</div>

<p>When you run this it will load the archived model, download and cache the evaluation dataset, and then make predictions:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>2017-08-23 19:49:18,451 - INFO - allennlp.models.archival - extracting archive file /tmp/tutorials/getting_started/model.tar.gz to temp dir /var/folders/_n/mdsjzvcs6s705kpn87f399880000gp/T/tmptgu44ulc
2017-08-23 19:49:18,643 - INFO - allennlp.commands.evaluate - Reading evaluation data from https://allennlp.s3.amazonaws.com/datasets/getting-started/sentences.small.test
2017-08-23 19:49:18,643 - INFO - allennlp.common.file_utils - https://allennlp.s3.amazonaws.com/datasets/getting-started/sentences.small.test not found in cache, downloading to /Users/joelg/.allennlp/datasets/aHR0cHM6Ly9hbGxlbm5scC5zMy5hbWF6b25hd3MuY29tL2RhdGFzZXRzL2dldHRpbmctc3RhcnRlZC9zZW50ZW5jZXMuc21hbGwudGVzdA==
100%|████████████████████████████████████████████████████████████████████████████████████| 170391/170391 [00:00&lt;00:00, 1306579.69B/s]
2017-08-23 19:49:20,203 - INFO - allennlp.data.dataset_readers.sequence_tagging - Reading instances from lines in file at: /Users/joelg/.allennlp/datasets/aHR0cHM6Ly9hbGxlbm5scC5zMy5hbWF6b25hd3MuY29tL2RhdGFzZXRzL2dldHRpbmctc3RhcnRlZC9zZW50ZW5jZXMuc21hbGwudGVzdA==
1000it [00:00, 36100.84it/s]
2017-08-23 19:49:20,233 - INFO - allennlp.data.dataset - Indexing dataset
100%|██████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00&lt;00:00, 7155.68it/s]
2017-08-23 19:49:20,373 - INFO - allennlp.commands.evaluate - Iterating over dataset
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:05&lt;00:00,  5.47it/s]
2017-08-23 19:49:26,228 - INFO - allennlp.commands.evaluate - Finished evaluating.
2017-08-23 19:49:26,228 - INFO - allennlp.commands.evaluate - Metrics:
2017-08-23 19:49:26,228 - INFO - allennlp.commands.evaluate - accuracy: 0.9070572302753674
2017-08-23 19:49:26,228 - INFO - allennlp.commands.evaluate - accuracy3: 0.9681496714651151
</code></pre>
</div>

<p>There is also a command line option to use a GPU, if you have one.</p>

<h3 id="making-predictions">Making Predictions</h3>

<p>TODO(joelgrus): write this part</p>

<h3 id="next-steps">Next Steps</h3>

<p>Continue on to the <a href="http://allennlp.org/tutorials/configuring-experiments">Configuring Experiments</a> tutorial.</p>
